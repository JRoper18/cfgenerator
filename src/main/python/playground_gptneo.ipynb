{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting kernel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from utils import ProgramDataset, make_max_length\n",
    "print(\"Starting kernel\")\n",
    "model_run_name = \"l2cfg\"\n",
    "param_size = \"125M\"\n",
    "model_dir = \"../../../output/gpt-results-%s-%s\" % (param_size, model_run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable, Iterator\n",
    "from functools import reduce\n",
    "def canBeList(x):\n",
    "    return isinstance(x, Iterable)\n",
    "\n",
    "def expand_iters(e):\n",
    "    if(canBeList(e)): # Expand it out.\n",
    "        return [expand_iters(ele) for ele in e]\n",
    "    return e\n",
    "def mapt(f, x):\n",
    "    if(len(x) == 0):\n",
    "        return f(x)\n",
    "    # TODO: this\n",
    "    return x\n",
    "def cons(a, b):\n",
    "    blist = canBeList(b)\n",
    "    alist = canBeList(a)\n",
    "    al = expand_iters(a) if alist else [a]\n",
    "    bl = expand_iters(b) if blist else [b]\n",
    "    return al + bl\n",
    "\n",
    "foldl = lambda f, acc, xs: reduce(f, xs, acc)\n",
    "foldr = lambda f, acc, xs: reduce(lambda x, y: f(y, x), xs[::-1], acc)\n",
    "def recl(f, e, x):\n",
    "    if(len(x) == 0):\n",
    "        return e\n",
    "    return f(x[0], x[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now, make the outputs for us to evaluate:\n",
    "fine_model = GPTNeoForCausalLM.from_pretrained(model_dir).cuda()\n",
    "fine_tokenizer = GPT2Tokenizer.from_pretrained(model_dir, \n",
    "    bos_token=\"<|startoftext|>\",\n",
    "    eos_token=\"<|endoftext|>\",\n",
    "    pad_token=\"<|pad|>\"\n",
    ")\n",
    "\n",
    "def do_gpt(seed_text):\n",
    "    input_tensor = fine_tokenizer(seed_text, return_tensors=\"pt\").input_ids.cuda()\n",
    "    outputs = fine_model.generate(\n",
    "        input_tensor, \n",
    "        max_length=2048,  \n",
    "        # num_return_sequences=5,\n",
    "        # no_repeat_ngram_size=2,\n",
    "        # repetition_penalty=1.5,\n",
    "        top_p=0.95,\n",
    "        temperature=0.05,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        # early_stopping=False\n",
    "    )\n",
    "    output = outputs[0]\n",
    "    out_str = fine_tokenizer.decode(output) \n",
    "    out_prog = out_str.split('Program:')[1].replace(\"<|endoftext|>\", \"\")\n",
    "    return out_prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_174038/1510298747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \t\t\"\"\"\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_174038/2939461689.py\u001b[0m in \u001b[0;36mdo_gpt\u001b[0;34m(seed_text)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mout_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout_prog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Program:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<|endoftext|>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_prog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "longstr = \"\"\"\n",
    "Examples:\n",
    "Inputs: \n",
    "[9, 14, -12, 7, 8]\n",
    "Output: \n",
    "[9, 14, -12, 7, 8, 9, 14, -12, 7, 8]\n",
    "Inputs: \n",
    "[-14, 3]\n",
    "Output: \n",
    "[-14, 3, -14, 3]\n",
    "Inputs: \n",
    "[-9, 13, -19, -4, 14]\n",
    "Output: \n",
    "[-9, 13, -19, -4, 14, -9, 13, -19, -4, 14]\n",
    "Inputs: \n",
    "[6, -14]\n",
    "Output: \n",
    "[6, -14, 6, -14]\n",
    "Inputs: \n",
    "[5, -7]\n",
    "Output: \n",
    "[5, -7, 5, -7]\n",
    "Inputs: \n",
    "[-14, 20, -11]\n",
    "Output: \n",
    "[-14, 20, -11, -14, 20, -11]\n",
    "Inputs: \n",
    "[17]\n",
    "Output: \n",
    "[17, 17]\n",
    "\n",
    "Program:\n",
    "\"\"\"\n",
    "\n",
    "# Original program: \n",
    "\"\"\"\n",
    "\n",
    "Program: \n",
    "<prog> -> \"lambda\" <lamargs> \":\" <stmt> ATTRS: {retType=[[int]], y_is_decl=true}\n",
    "\t\"lambda\" ->  ATTRS: {}\n",
    "\t<lamargs> -> <varInit> ATTRS: {length=1, y_is_decl=true}\n",
    "\t\t<varInit> -> <lowercaseAscii> ATTRS: {y_is_decl=true}\n",
    "\t\t\t<lowercaseAscii> -> \"y\" ATTRS: {chosenSymbol=y, retType=[[int]]}\n",
    "\t\t\t\t\"y\" ->  ATTRS: {}\n",
    "\t\":\" ->  ATTRS: {}\n",
    "\t<stmt> -> \"cons\" \"(\" <declared> \",\" <declared> \")\" ATTRS: {retType=[[int]], y_is_decl=true}\n",
    "\t\t\"cons\" ->  ATTRS: {}\n",
    "\t\t\"(\" ->  ATTRS: {}\n",
    "\t\t<declared> -> <lowercaseAscii> ATTRS: {chosenSymbol=y, retType=[[int]], y_is_decl=true}\n",
    "\t\t\t<lowercaseAscii> -> \"y\" ATTRS: {chosenSymbol=y, retType=[[int]], y_is_decl=true}\n",
    "\t\t\t\t\"y\" ->  ATTRS: {}\n",
    "\t\t\",\" ->  ATTRS: {}\n",
    "\t\t<declared> -> <lowercaseAscii> ATTRS: {chosenSymbol=y, retType=[[int]], y_is_decl=true}\n",
    "\t\t\t<lowercaseAscii> -> \"y\" ATTRS: {chosenSymbol=y, retType=[[int]], y_is_decl=true}\n",
    "\t\t\t\t\"y\" ->  ATTRS: {}\n",
    "\t\t\")\" ->  ATTRS: {}\n",
    "\t\t\"\"\"\n",
    "\n",
    "out = do_gpt(longstr)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1530148321.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_174038/1530148321.py\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    func = eval(prog_py)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "cartp = \"\"\"\n",
    "Inputs: \n",
    "[[1], [2, 3]]\n",
    "Outputs:\n",
    "[[1, 2], [1, 3]]\n",
    "Inputs: \n",
    "[[]]\n",
    "Outputs:\n",
    "[]\n",
    "Inputs: \n",
    "[[1, 2, 3], [4, 5]]\n",
    "Output:\n",
    "[[1, 4], [1, 5], [2, 4], [2, 5], [3, 4], [3, 5]]\n",
    "Inputs: \n",
    "[[1], [2, 3], [4, 5]]\n",
    "Output:\n",
    "[[1, 2, 4], [1, 2, 5], [1, 3, 4], [1, 3, 5]]\n",
    "\n",
    "Program:\n",
    "\"\"\"\n",
    "\n",
    "    func = eval(prog_py)\n",
    "    print(expand_iters(func([[1, 2, 3], [4, 5]])))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2282e338ecec3ece71c2002cd0caa8a2ea177485a557703c3a2b1c6e231f9179"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('gpt': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
