{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting kernel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from utils import ProgramDataset, make_max_length\n",
    "print(\"Starting kernel\")\n",
    "model_run_name = \"l2\"\n",
    "param_size = \"125M\"\n",
    "model_dir = \"../../../output/gpt-results-%s-%s\" % (param_size, model_run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable, Iterator\n",
    "from functools import reduce\n",
    "def canBeList(x):\n",
    "    return isinstance(x, Iterable)\n",
    "\n",
    "def expand_iters(e):\n",
    "    if(canBeList(e)): # Expand it out.\n",
    "        return [expand_iters(ele) for ele in e]\n",
    "    return e\n",
    "def mapt(f, x):\n",
    "    if(len(x) == 0):\n",
    "        return f(x)\n",
    "    # TODO: this\n",
    "    return x\n",
    "def cons(a, b):\n",
    "    blist = canBeList(b)\n",
    "    alist = canBeList(a)\n",
    "    al = expand_iters(a) if alist else [a]\n",
    "    bl = expand_iters(b) if blist else [b]\n",
    "    return al + bl\n",
    "\n",
    "foldl = lambda f, acc, xs: reduce(f, xs, acc)\n",
    "foldr = lambda f, acc, xs: reduce(lambda x, y: f(y, x), xs[::-1], acc)\n",
    "def recl(f, e, x):\n",
    "    if(len(x) == 0):\n",
    "        return e\n",
    "    return f(x[0], x[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "lambda q    : recl ( lambda q   , u    : map ( lambda q    : q    , u   )  , -33  , q   )  \n",
      "\n",
      "[[4, 5]]\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"\"\"\n",
    "Inputs: \n",
    "[[1], [2, 3]]\n",
    "Outputs:\n",
    "[[1, 2], [1, 3]]\n",
    "Inputs: \n",
    "[[]]\n",
    "Outputs:\n",
    "[]\n",
    "Inputs: \n",
    "[[1, 2, 3], [4, 5]]\n",
    "Output:\n",
    "[[1, 4], [1, 5], [2, 4], [2, 5], [3, 4], [3, 5]]\n",
    "Inputs: \n",
    "[[1], [2, 3], [4, 5]]\n",
    "Output:\n",
    "[[1, 2, 4], [1, 2, 5], [1, 3, 4], [1, 3, 5]]\n",
    "\n",
    "Program:\n",
    "\"\"\"\n",
    "\n",
    "# Now, make the outputs for us to evaluate:\n",
    "fine_model = GPTNeoForCausalLM.from_pretrained(model_dir).cuda()\n",
    "fine_tokenizer = GPT2Tokenizer.from_pretrained(model_dir, \n",
    "    bos_token=\"<|startoftext|>\",\n",
    "    eos_token=\"<|endoftext|>\",\n",
    "    pad_token=\"<|pad|>\"\n",
    ")\n",
    "input_tensor = fine_tokenizer(seed_text, return_tensors=\"pt\").input_ids.cuda()\n",
    "outputs = fine_model.generate(\n",
    "    input_tensor, \n",
    "    max_length=2048,  \n",
    "    # num_return_sequences=5,\n",
    "    # no_repeat_ngram_size=2,\n",
    "    # repetition_penalty=1.5,\n",
    "    top_p=0.95,\n",
    "    temperature=0.05,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    # early_stopping=False\n",
    ")\n",
    "# Print generated descriptions\n",
    "for i, output in enumerate(outputs):\n",
    "    out_str = fine_tokenizer.decode(output) \n",
    "    out_prog = out_str.split('Program:')[1].replace(\"<|endoftext|>\", \"\")\n",
    "    prog_py = out_prog\n",
    "    print(\"{}: {}\".format(i, out_prog))\n",
    "    func = eval(prog_py)\n",
    "    print(expand_iters(func([[1, 2, 3], [4, 5]])))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2282e338ecec3ece71c2002cd0caa8a2ea177485a557703c3a2b1c6e231f9179"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('gpt': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
